---
title: "Independence of sigma-algebras"
description: "A condition ensuring events measurable with respect to different sigma-algebras are independent"
---

Two **sigma-algebras are independent** if, on a {{< knowl id="probability-space" text="probability space" >}} $(\Omega,\mathcal F,\mathbb P)$, sub-{{< knowl id="sigma-algebra" section="measure-theory" text="sigma-algebras" >}} $\mathcal G_1,\mathcal G_2\subseteq\mathcal F$ satisfy
$$
\mathbb P(A\cap B)\;=\;\mathbb P(A)\,\mathbb P(B)\quad\text{for all }A\in\mathcal G_1,\;B\in\mathcal G_2.
$$

A family $(\mathcal G_i)_{i\in I}$ of sub-$\sigma$-algebras is **independent** if for every finite subset $\{i_1,\dots,i_n\}\subseteq I$ and every choice of events $A_k\in \mathcal G_{i_k}$,
$$
\mathbb P\!\left(\bigcap_{k=1}^n A_k\right)\;=\;\prod_{k=1}^n \mathbb P(A_k).
$$

This formalizes “independence of information”: events determined by $\mathcal G_1$ do not influence probabilities of events determined by $\mathcal G_2$.  In particular, {{< knowl id="independence-random-variables" text="independence of random variables" >}} $X$ and $Y$ can be characterized by independence of the generated $\sigma$-algebras $\sigma(X)$ and $\sigma(Y)$.

**Examples:**
- In two independent coin flips, let $\mathcal G_1$ be the $\sigma$-algebra generated by the first flip and $\mathcal G_2$ the $\sigma$-algebra generated by the second flip. Then $\mathcal G_1$ and $\mathcal G_2$ are independent.
- If $\mathcal G_2\subseteq \mathcal G_1$ and $\mathcal G_2$ contains an event $B$ with $\mathbb P(B)\in(0,1)$, then $\mathcal G_1$ and $\mathcal G_2$ are not independent (since taking $A=B$ violates $\mathbb P(A\cap B)=\mathbb P(A)\mathbb P(B)$).
