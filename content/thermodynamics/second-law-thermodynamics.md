---
title: "Second law of thermodynamics"
description: "Introduces entropy and constrains which processes are possible by requiring nonnegative entropy production."
---

## Definition (entropy formulation)

For every equilibrium {{< knowl id="thermodynamic-state" text="thermodynamic state" >}} of a {{< knowl id="thermodynamic-system" text="thermodynamic system" >}}, the second law asserts the existence of a state function $S$ called the {{< knowl id="thermodynamic-entropy" text="thermodynamic entropy" >}} such that, for any {{< knowl id="thermodynamic-process" text="thermodynamic process" >}} taking the system from equilibrium state $A$ to equilibrium state $B$,
$$
S(B)-S(A)\;\ge\;\int_A^B \frac{\delta Q}{T_{\mathrm{b}}}.
$$

Here $\delta Q$ is the (inexact) heat absorbed by the system (see {{< knowl id="heat-inexact-differential" text="heat" >}}), and $T_{\mathrm{b}}$ is the {{< knowl id="temperature-thermo" text="temperature" >}} at the boundary where that heat is exchanged (often set by a {{< knowl id="thermal-reservoir" text="thermal reservoir" >}}).

Equality holds if and only if the process is {{< knowl id="reversible-process" text="reversible" >}}; strict inequality signals {{< knowl id="irreversible-process" text="irreversibility" >}}.

A particularly transparent form is obtained by treating “system + {{< knowl id="surroundings-environment" text="surroundings" >}}” as an {{< knowl id="isolated-system" text="isolated system" >}}: then the second law becomes
$$
\Delta S_{\text{total}} \ge 0,
$$
so the total entropy cannot decrease.

## Physical interpretation

The second law is the thermodynamic expression of an “arrow of time”: macroscopic processes have a preferred direction because irreversibility produces entropy. Energy conservation alone (the {{< knowl id="first-law-thermodynamics" text="first law" >}}) does not forbid processes that run “backwards,” but the second law does.

Operationally, the law is equivalent to the impossibility of certain cyclic devices, captured by the {{< knowl id="kelvin-planck-statement" text="Kelvin–Planck statement" >}} and the {{< knowl id="clausius-statement-second-law" text="Clausius statement" >}}. The mathematical backbone connecting these formulations is the {{< knowl id="clausius-inequality" text="Clausius inequality" >}}.

## Key relations and consequences

- **Entropy balance / entropy production.** Any process can be written as
  $$
  \Delta S = \int \frac{\delta Q}{T_{\mathrm{b}}} + S_{\mathrm{gen}},
  $$

  where $S_{\mathrm{gen}}\ge 0$ is entropy generated by irreversibility (and $S_{\mathrm{gen}}=0$ characterizes reversibility).

- **Isolated and adiabatic implications.** For an {{< knowl id="isolated-system" text="isolated system" >}}, $\Delta S\ge 0$. For a closed system insulated by an {{< knowl id="adiabatic-wall" text="adiabatic wall" >}} (so $\delta Q=0$), one likewise has $\Delta S\ge 0$.

- **Free-energy monotonicity (common equilibrium criteria).** For a closed system in contact with a thermal reservoir at fixed $T$, the {{< knowl id="helmholtz-free-energy" text="Helmholtz free energy" >}} (built from {{< knowl id="internal-energy-thermo" text="internal energy" >}} and entropy) satisfies $\Delta F\le 0$ for spontaneous changes at fixed $T,V,N$. At fixed $T,p,N$, the {{< knowl id="gibbs-free-energy" text="Gibbs free energy" >}} (built from {{< knowl id="enthalpy" text="enthalpy" >}} and entropy) satisfies $\Delta G\le 0$.

- **Statistical-mechanical viewpoint.** Many microscopic derivations connect “entropy never decreases” to the nonnegativity of information measures such as {{< knowl id="relative-entropy-kl-divergence" section="probability" text="relative entropy (KL divergence)" >}} (see also {{< knowl id="gibbs-inequality-kl" section="probability" text="Gibbs inequality" >}}) and to the identification of $S/k_B$ with an entropy-like quantity (compare {{< knowl id="shannon-entropy" section="probability" text="Shannon entropy" >}}).
